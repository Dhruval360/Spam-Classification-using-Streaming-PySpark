{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "# Text cleaning and preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30344, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./spam/train.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Spam/Ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transfers from ees</td>\n",
       "      <td>attached is the latest version of the cost cen...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fw : re ivanhoe e . s . d</td>\n",
       "      <td>fyi , kim .\\n- - - - - original message - - - ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re : enerfin meter 980439 for 10 / 00</td>\n",
       "      <td>it did but tetco prorated the flow between the...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meoh plant status</td>\n",
       "      <td>the methanol plant has determined extensive re...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>re : tenaska iv</td>\n",
       "      <td>i tried calling you this am but your phone rol...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Subject  \\\n",
       "0                     transfers from ees   \n",
       "1              fw : re ivanhoe e . s . d   \n",
       "2  re : enerfin meter 980439 for 10 / 00   \n",
       "3                      meoh plant status   \n",
       "4                        re : tenaska iv   \n",
       "\n",
       "                                             Message Spam/Ham  \n",
       "0  attached is the latest version of the cost cen...     spam  \n",
       "1  fyi , kim .\\n- - - - - original message - - - ...     spam  \n",
       "2  it did but tetco prorated the flow between the...      ham  \n",
       "3  the methanol plant has determined extensive re...      ham  \n",
       "4  i tried calling you this am but your phone rol...     spam  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['Message'][:5000], df['Spam/Ham'][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have list of texts, that encoded binary. Using 'decode' is one of possible solutions, but some texts don't allow us to apply decoding. This can be solved by deleting these texts, but because of this, we can lose important information. Instead of this we can do following:\n",
    "\n",
    "* We should remove all special symbols.\n",
    "* Remove 'b' in beginning of each text\n",
    "* Replace all gaps (\\t, \\n, \\r, \\f) between words with spaces\n",
    "* Remove all non-letters characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3018b792ad7945f4956ce57ace0f4b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create corpus\n",
    "corpus = []\n",
    "for i in tqdm(range(0, len(X))):\n",
    "    # Remove special symbols\n",
    "    review = re.sub(r'\\\\r\\\\n', ' ', str(X[i]))\n",
    "    # Remove all symbols except letters\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    # Replacing all gaps with spaces \n",
    "    review = re.sub(r'\\s+', ' ', review)                    \n",
    "    # Remove 'b' in the beginning of each text\n",
    "    review = re.sub(r'^b\\s+', '', review)       \n",
    "\n",
    "    review = review.lower().split()\n",
    "    review = [stemmer.stem(word) for word in review if word not in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "#tf = TfidfVectorizer()\n",
    "\n",
    "# Creating the Bag of Words model\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data on train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  random_state=9, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Naive Bayes model as the likelihood of whether an email is spam or ham is an aposterior probability and they usually show high performance in spam detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.979\n",
      "precision: 0.962\n",
      "recall: 1.000\n",
      "confusion matrix: \n",
      "[[452  21]\n",
      " [  0 527]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred, pos_label = 'spam')\n",
    "recall = recall_score(y_test, pred, pos_label = 'spam')\n",
    "conf_m = confusion_matrix(y_test, pred)\n",
    "\n",
    "print(f\"accuracy: %.3f\" %accuracy)\n",
    "print(f\"precision: %.3f\" %precision)\n",
    "print(f\"recall: %.3f\" %recall)\n",
    "print(f\"confusion matrix: \")\n",
    "print(conf_m)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96287154c02bd33d964264908876ff144eece4cbcf76f7700a55934c72d2f956"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
